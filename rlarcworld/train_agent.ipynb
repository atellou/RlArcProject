{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.data.replay_buffers import (\n",
    "    TensorDictReplayBuffer,\n",
    "    LazyTensorStorage,\n",
    "    PrioritizedSampler,\n",
    ")\n",
    "from tensordict import TensorDict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "from rlarcworld.arc_dataset import ArcDataset, ArcSampleTransformer\n",
    "from rlarcworld.enviroments.arc_batch_grid_env import ArcBatchGridEnv\n",
    "from rlarcworld.enviroments.wrappers.rewards import PixelAwareRewardWrapper\n",
    "from rlarcworld.agent.actor import ArcActorNetwork\n",
    "from rlarcworld.agent.critic import ArcCriticNetwork\n",
    "\n",
    "from rlarcworld.algorithms.d4pg import D4PG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 30\n",
    "color_values = 11\n",
    "batch_size=128\n",
    "max_steps = torch.randint(30, 100, size=(1,)).item()\n",
    "n_steps = torch.randint(3, 20 // 2, size=(1,)).item()\n",
    "gamma = 0.99\n",
    "env = ArcBatchGridEnv(grid_size, color_values, n_steps=n_steps, gamma=gamma)\n",
    "env = PixelAwareRewardWrapper(env, n_steps=n_steps, gamma=gamma)\n",
    "\n",
    "# Create an instance of the ArcDataset\n",
    "dataset = ArcDataset(\n",
    "    arc_dataset_dir=\"./dataset/training\",\n",
    "    keep_in_memory=False,\n",
    "    transform=ArcSampleTransformer(\n",
    "        (grid_size, grid_size), examples_stack_dim=10\n",
    "    ),\n",
    ")\n",
    "train_samples = DataLoader(dataset=dataset, batch_size=len(dataset) // 2)\n",
    "\n",
    "dataset_val = ArcDataset(\n",
    "    arc_dataset_dir=\"./dataset/evaluation\",\n",
    "    keep_in_memory=False,\n",
    "    transform=ArcSampleTransformer(\n",
    "        (grid_size, grid_size), examples_stack_dim=10\n",
    "    ),\n",
    ")\n",
    "val_samples = DataLoader(dataset=dataset, batch_size=len(dataset) // 2)\n",
    "replay_buffer = TensorDictReplayBuffer(\n",
    "    storage=LazyTensorStorage(batch_size),\n",
    "    sampler=PrioritizedSampler(\n",
    "        max_capacity=batch_size,\n",
    "        alpha=1.0,\n",
    "        beta=1.0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "num_atoms = {\"pixel_wise\": 50, \"binary\": 3, \"n_reward\": 50 * n_steps}\n",
    "v_min = {\"pixel_wise\": -40, \"binary\": 0, \"n_reward\": -40 * n_steps}\n",
    "v_max = {\"pixel_wise\": 2, \"binary\": 1, \"n_reward\": 2 * n_steps}\n",
    "critic = ArcCriticNetwork(\n",
    "    size=grid_size,\n",
    "    color_values=color_values,\n",
    "    num_atoms=num_atoms,\n",
    "    v_min=v_min,\n",
    "    v_max=v_max,\n",
    ")\n",
    "\n",
    "actor = ArcActorNetwork(size=grid_size, color_values=color_values)\n",
    "d4pg = D4PG(\n",
    "    env=env,\n",
    "    actor=actor,\n",
    "    critic=critic,\n",
    "    train_samples=train_samples,\n",
    "    validation_samples=val_samples,\n",
    "    batch_size=batch_size,\n",
    "    replay_buffer=replay_buffer,\n",
    "    target_update_frequency=5,\n",
    "    n_steps=env.n_steps,\n",
    "    gamma=env.gamma,\n",
    "    tb_writer=SummaryWriter(log_dir=\"runs/test_validation_d4pg\"),\n",
    ")\n",
    "d4pg.fit(\n",
    "    max_steps=max_steps,\n",
    "    validation_steps_frequency=10,\n",
    "    validation_steps_per_train_step=10,\n",
    "    validation_steps_per_episode=max_steps,\n",
    "    logger_frequency=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_nested_ref\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isdir(\n",
    "    \"./runs/test_validation_d4pg\"\n",
    "), \"Directory 'runs/test_validation_d4pg' does not exist\"\n",
    "\n",
    "ref, last_key = get_nested_ref(\n",
    "    d4pg.history, \"Validation/Reward\"\n",
    ")\n",
    "assert isinstance(\n",
    "    ref[last_key], dict\n",
    "), \"Invalid validation reward history format - expected dict, got {}\".format(\n",
    "    type(ref[last_key])\n",
    ")\n",
    "assert isinstance(\n",
    "    ref[last_key][\"n_reward\"], np.ndarray\n",
    "), \"Invalid validation reward history format - expected np.ndarray for n_step, got {}\".format(\n",
    "    type(ref[last_key].get(\"n_step\", None))\n",
    ")\n",
    "\n",
    "ref, last_key = get_nested_ref(\n",
    "    d4pg.history, \"Train/Reward\"\n",
    ")\n",
    "\n",
    "assert isinstance(\n",
    "    ref[last_key], dict\n",
    "), \"Invalid training reward history format - expected dict, got {}\".format(\n",
    "    type(ref[last_key])\n",
    ")\n",
    "assert isinstance(\n",
    "    ref[last_key][\"n_reward\"], np.ndarray\n",
    "), \"Invalid training reward history format - expected np.ndarray for n_step, got {}\".format(\n",
    "    type(ref[last_key].get(\"n_step\", None))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(low=0, high=2, size=(10, 1))\n",
    "print(x)\n",
    "print(torch.count_nonzero(x == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andresftu/.cache/pypoetry/virtualenvs/rlarcworld-ADz4tFzs-py3.13/lib/python3.13/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "transformer_model = torch.nn.Transformer(nhead=16, num_encoder_layers=12)\n",
    "src = torch.rand((10, 32, 512))\n",
    "tgt = torch.rand((20, 32, 512))\n",
    "out = transformer_model(src, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 32, 512])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 10, 30, 30])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(20,10,2,30,30)[:,:, 0, :,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the ArcDataset\n",
    "dataset = ArcDataset(\n",
    "    arc_dataset_dir=\"./dataset/training\",\n",
    "    keep_in_memory=False,\n",
    "    transform=ArcSampleTransformer(\n",
    "        (30, 30), examples_stack_dim=10\n",
    "    ),\n",
    ")\n",
    "train_samples = DataLoader(dataset=dataset, batch_size=len(dataset) // 2)\n",
    "\n",
    "dataset_val = ArcDataset(\n",
    "    arc_dataset_dir=\"./dataset/evaluation\",\n",
    "    keep_in_memory=False,\n",
    "    transform=ArcSampleTransformer(\n",
    "        (30, 30), examples_stack_dim=10\n",
    "    ),\n",
    ")\n",
    "val_samples = DataLoader(dataset=dataset, batch_size=len(dataset) // 2)\n",
    "replay_buffer = TensorDictReplayBuffer(\n",
    "    storage=LazyTensorStorage(100),\n",
    "    sampler=PrioritizedSampler(\n",
    "        max_capacity=1000,\n",
    "        alpha=1.0,\n",
    "        beta=1.0,\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer.sampler.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Blob: rl_arc_project, dataset/testing/d017b73f.json, 1740323185131824>, <Blob: rl_arc_project, dataset/testing/d19f7514.json, 1740323183346837>, <Blob: rl_arc_project, dataset/testing/d282b262.json, 1740323201380632>, <Blob: rl_arc_project, dataset/testing/d304284e.json, 1740323181627699>, <Blob: rl_arc_project, dataset/testing/d37a1ef5.json, 1740323202993398>, <Blob: rl_arc_project, dataset/testing/d47aa2ff.json, 1740323196706985>, <Blob: rl_arc_project, dataset/testing/d492a647.json, 1740323173226719>, <Blob: rl_arc_project, dataset/testing/d56f2372.json, 1740323188471501>, <Blob: rl_arc_project, dataset/testing/d5c634a2.json, 1740323191956951>, <Blob: rl_arc_project, dataset/testing/d931c21c.json, 1740323175021665>, <Blob: rl_arc_project, dataset/testing/d94c3b52.json, 1740323177593331>, <Blob: rl_arc_project, dataset/testing/da2b0fe3.json, 1740323194450322>, <Blob: rl_arc_project, dataset/testing/da515329.json, 1740323194553274>, <Blob: rl_arc_project, dataset/testing/dc2aa30b.json, 1740323195593980>, <Blob: rl_arc_project, dataset/testing/dc2e9a9d.json, 1740323192281941>, <Blob: rl_arc_project, dataset/testing/dd2401ed.json, 1740323188674424>, <Blob: rl_arc_project, dataset/testing/de493100.json, 1740323187395526>, <Blob: rl_arc_project, dataset/testing/df8cc377.json, 1740323205384686>, <Blob: rl_arc_project, dataset/testing/e0fb7511.json, 1740323197981662>, <Blob: rl_arc_project, dataset/testing/e133d23d.json, 1740323193243148>, <Blob: rl_arc_project, dataset/testing/e1baa8a4.json, 1740323175088453>, <Blob: rl_arc_project, dataset/testing/e1d2900e.json, 1740323191956391>, <Blob: rl_arc_project, dataset/testing/e2092e0c.json, 1740323202142316>, <Blob: rl_arc_project, dataset/testing/e21a174a.json, 1740323177640566>, <Blob: rl_arc_project, dataset/testing/e345f17b.json, 1740323189898576>, <Blob: rl_arc_project, dataset/testing/e4075551.json, 1740323204064731>, <Blob: rl_arc_project, dataset/testing/e41c6fd3.json, 1740323204121564>, <Blob: rl_arc_project, dataset/testing/e57337a4.json, 1740323186058147>, <Blob: rl_arc_project, dataset/testing/e5790162.json, 1740323194530396>, <Blob: rl_arc_project, dataset/testing/e5c44e8f.json, 1740323189144710>, <Blob: rl_arc_project, dataset/testing/e619ca6e.json, 1740323191477242>, <Blob: rl_arc_project, dataset/testing/e633a9e5.json, 1740323197954698>, <Blob: rl_arc_project, dataset/testing/e66aafb8.json, 1740323196863391>, <Blob: rl_arc_project, dataset/testing/e681b708.json, 1740323176353564>, <Blob: rl_arc_project, dataset/testing/e69241bd.json, 1740323186629095>, <Blob: rl_arc_project, dataset/testing/e6de6e8f.json, 1740323178959655>, <Blob: rl_arc_project, dataset/testing/e74e1818.json, 1740323182273904>, <Blob: rl_arc_project, dataset/testing/e760a62e.json, 1740323180323243>, <Blob: rl_arc_project, dataset/testing/e7639916.json, 1740323176521364>, <Blob: rl_arc_project, dataset/testing/e78887d1.json, 1740323190927994>, <Blob: rl_arc_project, dataset/testing/e7a25a18.json, 1740323176268985>, <Blob: rl_arc_project, dataset/testing/e7b06bea.json, 1740323185281186>, <Blob: rl_arc_project, dataset/testing/e7dd8335.json, 1740323178974193>, <Blob: rl_arc_project, dataset/testing/e872b94a.json, 1740323198061043>, <Blob: rl_arc_project, dataset/testing/e88171ec.json, 1740323202231857>, <Blob: rl_arc_project, dataset/testing/e95e3d8e.json, 1740323180389837>, <Blob: rl_arc_project, dataset/testing/e99362f0.json, 1740323202328176>, <Blob: rl_arc_project, dataset/testing/e9ac8c9e.json, 1740323173619410>, <Blob: rl_arc_project, dataset/testing/e9b4f6fc.json, 1740323203169602>, <Blob: rl_arc_project, dataset/testing/e9bb6954.json, 1740323200046799>, <Blob: rl_arc_project, dataset/testing/e9c9d9a1.json, 1740323204191973>, <Blob: rl_arc_project, dataset/testing/ea959feb.json, 1740323180249875>, <Blob: rl_arc_project, dataset/testing/ea9794b1.json, 1740323174994209>, <Blob: rl_arc_project, dataset/testing/ecaa0ec1.json, 1740323183802407>, <Blob: rl_arc_project, dataset/testing/ed74f2f2.json, 1740323178969614>, <Blob: rl_arc_project, dataset/testing/ed98d772.json, 1740323204973438>, <Blob: rl_arc_project, dataset/testing/ef26cbf6.json, 1740323193304502>, <Blob: rl_arc_project, dataset/testing/f0afb749.json, 1740323184820494>, <Blob: rl_arc_project, dataset/testing/f0df5ff0.json, 1740323186176017>, <Blob: rl_arc_project, dataset/testing/f21745ec.json, 1740323201291035>, <Blob: rl_arc_project, dataset/testing/f3b10344.json, 1740323182410269>, <Blob: rl_arc_project, dataset/testing/f3cdc58f.json, 1740323199001359>, <Blob: rl_arc_project, dataset/testing/f3e62deb.json, 1740323187804932>, <Blob: rl_arc_project, dataset/testing/f4081712.json, 1740323195697952>, <Blob: rl_arc_project, dataset/testing/f45f5ca7.json, 1740323201113549>, <Blob: rl_arc_project, dataset/testing/f5aa3634.json, 1740323190479142>, <Blob: rl_arc_project, dataset/testing/f5c89df1.json, 1740323189810392>, <Blob: rl_arc_project, dataset/testing/f823c43c.json, 1740323198917857>, <Blob: rl_arc_project, dataset/testing/f83cb3f6.json, 1740323200183373>, <Blob: rl_arc_project, dataset/testing/f8be4b64.json, 1740323203276875>, <Blob: rl_arc_project, dataset/testing/f9a67cb5.json, 1740323190970488>, <Blob: rl_arc_project, dataset/testing/f9d67f8b.json, 1740323183986478>, <Blob: rl_arc_project, dataset/testing/fafd9572.json, 1740323193275008>, <Blob: rl_arc_project, dataset/testing/fb791726.json, 1740323187682753>, <Blob: rl_arc_project, dataset/testing/fc754716.json, 1740323196744557>, <Blob: rl_arc_project, dataset/testing/fd096ab6.json, 1740323200058548>, <Blob: rl_arc_project, dataset/testing/fd4b2b02.json, 1740323173367882>, <Blob: rl_arc_project, dataset/testing/fe9372f3.json, 1740323178018442>, <Blob: rl_arc_project, dataset/testing/fea12743.json, 1740323195782331>, <Blob: rl_arc_project, dataset/testing/ff72ca3e.json, 1740323199056435>]\n"
     ]
    }
   ],
   "source": [
    "gcs_bucket_name = \"rl_arc_project\"\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(gcs_bucket_name)\n",
    "bucket = storage_client.bucket(gcs_bucket_name)\n",
    "blobs = list(bucket.list_blobs(prefix=\"dataset/testing/\"))\n",
    "print(blobs)    \n",
    "# blob = bucket.blob(\"dataset/training/0.json\")\n",
    "# file_contents = blob.download_as_string()\n",
    "# sample = json.loads(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset/testing/d017b73f.json'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blobs[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import torch\n",
    "import os\n",
    "model = torch.nn.Linear(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"gs://rl_arc_project/runs/saved_models/test/\"\n",
    "bucket_name = path.split(\"gs://\")[-1]\n",
    "prefix = bucket_name.split(\"/\")\n",
    "bucket_name = prefix[0]\n",
    "prefix = \"/\".join(prefix[1:])\n",
    "\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket(bucket_name)\n",
    "blob = bucket.blob(os.path.join(prefix, \"actor.ptc\"))\n",
    "with blob.open(\"wb\", ignore_flush=True) as f:\n",
    "    torch.save(model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlarcworld-ADz4tFzs-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
